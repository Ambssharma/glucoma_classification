{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import *\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 597, 597, 3)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('CROPAUG2/glu/*.jpg')              #change '/'\n",
    "glu = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(glu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 597, 597, 3)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('CROPAUG2/nglu/*.jpg')         #change '/'\n",
    "nonglu = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(nonglu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 597, 597, 3)\n",
      "(597, 597, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((glu,nonglu),axis=0)\n",
    "print(X.shape)\n",
    "print(X[1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "gluL = np.array([1 for i in range(40)])\n",
    "nongluL = np.array([0 for i in range(50)])\n",
    "y = np.concatenate((gluL,nongluL),axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 597, 597, 3) (18, 597, 597, 3) (72,) (18,)\n",
      "[0 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subodh_pushkar/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dropout,Dense,LeakyReLU\n",
    "from keras.layers.core import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=X_train.shape[1:]))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Conv2D(32, (3,3),padding='valid'))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.04))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.08))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.08))\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv2D(256, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, (1,1)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 597, 597, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 597, 597, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 597, 597, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 595, 595, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 595, 595, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 595, 595, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 297, 297, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 295, 295, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 295, 295, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 295, 295, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 293, 293, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 293, 293, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 293, 293, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 146, 146, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 144, 144, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 144, 144, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 144, 144, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 70, 70, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 70, 70, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 70, 70, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 31, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 5, 5, 256)         65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 1,252,466\n",
      "Trainable params: 1,252,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subodh_pushkar/anaconda3/lib/python3.5/site-packages/keras_preprocessing/image.py:770: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "num_classes = 2\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_std_normalization=True,horizontal_flip=True, vertical_flip=True,\n",
    "                             rotation_range=15, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,zoom_range=0.1,\n",
    "                             fill_mode='constant', cval=0.0)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "print(y_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import *\n",
    "\n",
    "from keras import optimizers\n",
    "# sgd = optimizers.SGD(lr=0.0003, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='mean_squared_error', optimizer=sgd, metrics = ['accuracy'])\n",
    "# opt = Adam(lr=0.001)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# EPOCHS = 100\n",
    "# INIT_LR = 1e-4\n",
    "# BS = 32\n",
    "# opt = Adam(lr=INIT_LR)\n",
    "model.compile(optimizer=SGD(0.003),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "# train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/150\n",
      "72/72 [==============================] - 115s 2s/step - loss: 0.8261 - acc: 0.4236 - val_loss: 0.6954 - val_acc: 0.5556\n",
      "Epoch 2/150\n",
      "17/72 [======>.......................] - ETA: 1:22 - loss: 0.8044 - acc: 0.4118"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(datagen.flow(X_train, y_train, batch_size=1),\n",
    "                        validation_data=(X_test, y_test), steps_per_epoch=len(X_train), epochs=150, verbose=1)\n",
    "\n",
    "# model.fit(datagen.flow(X_train, y_train, batch_size=32),steps_per_epoch=len(X_train) / 32, epochs=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save('third_model.h5')\n",
    "\n",
    "# Deletes the existing model\n",
    "del model  \n",
    "\n",
    "# Returns a compiled model identical to the previous one\n",
    "model = load_model('third_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(H.history['loss'])\n",
    "plt.plot(H.history['val_loss'])\n",
    "plt.title('Training for ' +str(150)+ ' epochs')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(H.history['acc'])\n",
    "plt.plot(H.history['val_acc'])\n",
    "plt.title('Training for ' +str(150)+ ' epochs')\n",
    "plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    images_idx = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = np.asarray(Image.open(os.path.join(folder,filename)))\n",
    "        images.append(img)\n",
    "        images_idx.append(filename)\n",
    "    return images, images_idx\n",
    "    \n",
    "img , img_idx = load_images_from_folder('CROPTEST4/')\n",
    "test = np.asarray(img)\n",
    "print(test.shape)\n",
    "# print(img_idx)\n",
    "for i in range(400):\n",
    "    print(img_idx[i])\n",
    "# A=np.asarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model.predict(test, batch_size=1)\n",
    "print(ans)\n",
    "# model.predict_classes(test,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for list in ans:\n",
    "    if list[1]<0.2:\n",
    "        print(0.1)\n",
    "        continue\n",
    "    if list[1]<0.3:\n",
    "        print(0.2)\n",
    "        continue\n",
    "    if list[1]<0.35:\n",
    "        print(0.3)\n",
    "        continue\n",
    "    if list[1]<0.4:\n",
    "        print(0.4)\n",
    "        continue\n",
    "    if list[1]<0.5:\n",
    "        print(0.5)\n",
    "        continue\n",
    "    if list[1]<0.6:\n",
    "        print(0.6)\n",
    "        continue\n",
    "    if list[1]<0.65:\n",
    "        print(0.7)\n",
    "        continue\n",
    "    if list[1]<0.675:\n",
    "        print(0.8)\n",
    "        continue\n",
    "    if list[1]<0.69:\n",
    "        print(0.9)\n",
    "        continue\n",
    "    else:\n",
    "        print(1.0)\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model_feat = Model(inputs=model.input,outputs=model.get_layer('dense_1').output)\n",
    "\n",
    "feat_train = model_feat.predict(X_train)\n",
    "print(feat_train.shape)\n",
    "\n",
    "feat_val = model_feat.predict(X_test)\n",
    "print(feat_val.shape)\n",
    "\n",
    "feat_test = model_feat.predict(test)\n",
    "print(feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "svm.fit(feat_train,np.argmax(y_train,axis=1))\n",
    "\n",
    "print('fitting done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(feat_train,np.argmax(y_train,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(feat_val,np.argmax(y_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_labels = svm.predict(feat_test)\n",
    "print(Pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xb = xgb.XGBClassifier()\n",
    "\n",
    "xb.fit(feat_train,np.argmax(y_train,axis=1))\n",
    "\n",
    "print('fitting done !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.score(feat_train,np.argmax(y_train,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.score(feat_val,np.argmax(y_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_labels = xb.predict(feat_test)\n",
    "print(Pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
