{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import *\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 497, 497, 3)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('train/cropped/glu/*.jpg')              #change '/'\n",
    "glu = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(glu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 497, 497, 3)\n"
     ]
    }
   ],
   "source": [
    "filelist = glob.glob('train/cropped/nglu/*.jpg')         #change '/'\n",
    "nonglu = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "print(nonglu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 497, 497, 3)\n",
      "(497, 497, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((glu,nonglu),axis=0)\n",
    "print(X.shape)\n",
    "print(X[1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86,)\n"
     ]
    }
   ],
   "source": [
    "gluL = np.array([1 for i in range(40)])\n",
    "nongluL = np.array([0 for i in range(46)])\n",
    "y = np.concatenate((gluL,nongluL),axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 497, 497, 3) (18, 497, 497, 3) (68,) (18,)\n",
      "[0 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, Flatten, Dropout,Dense,LeakyReLU\n",
    "from keras.layers.core import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=X_train.shape[1:]))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(Conv2D(32, (3,3),padding='valid'))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.10))\n",
    "model.add(Conv2D(256, (3,3)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "# model.add(Dropout(0.15))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, (1,1)))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(LeakyReLU(alpha=0.05))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 497, 497, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 497, 497, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 495, 495, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 495, 495, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 247, 247, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 245, 245, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 245, 245, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 243, 243, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 243, 243, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 121, 121, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 119, 119, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 119, 119, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 57, 57, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 57, 57, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 26, 26, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 4, 4, 256)         65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 1,105,010\n",
      "Trainable params: 1,105,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "num_classes = 2\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True,\n",
    "                             rotation_range=15, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,zoom_range=0.1,\n",
    "                             fill_mode='constant', cval=0.0)\n",
    "\n",
    "# print(datagen.fit(X_train))\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# sgd = optimizers.SGD(lr=0.0003, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='mean_squared_error', optimizer=sgd, metrics = ['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.7075 - acc: 0.5074 - val_loss: 0.6988 - val_acc: 0.4444\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.7102 - acc: 0.4926 - val_loss: 0.6775 - val_acc: 0.5833\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.6699 - acc: 0.5809 - val_loss: 0.6526 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.6566 - acc: 0.6103 - val_loss: 0.6547 - val_acc: 0.6667\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.6841 - acc: 0.5588 - val_loss: 0.6443 - val_acc: 0.6667\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.6806 - acc: 0.5735 - val_loss: 0.7132 - val_acc: 0.4167\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.6519 - acc: 0.6324 - val_loss: 0.7513 - val_acc: 0.3611\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.6831 - acc: 0.6176 - val_loss: 0.6432 - val_acc: 0.6667\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.6149 - acc: 0.6765 - val_loss: 0.8349 - val_acc: 0.3889\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 66s 963ms/step - loss: 0.5938 - acc: 0.6985 - val_loss: 0.8194 - val_acc: 0.3889\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 65s 961ms/step - loss: 0.6052 - acc: 0.6838 - val_loss: 0.6118 - val_acc: 0.7222\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5897 - acc: 0.6985 - val_loss: 0.6275 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.6000 - acc: 0.7059 - val_loss: 0.6767 - val_acc: 0.5556\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5751 - acc: 0.7353 - val_loss: 0.6325 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5845 - acc: 0.7353 - val_loss: 0.6799 - val_acc: 0.6111\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5709 - acc: 0.7500 - val_loss: 0.6124 - val_acc: 0.6667\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5820 - acc: 0.7353 - val_loss: 0.5988 - val_acc: 0.7222\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5735 - acc: 0.7647 - val_loss: 0.5938 - val_acc: 0.7222\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5549 - acc: 0.7132 - val_loss: 0.5842 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5117 - acc: 0.8235 - val_loss: 0.6158 - val_acc: 0.6389\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5717 - acc: 0.7059 - val_loss: 0.6024 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5543 - acc: 0.7647 - val_loss: 0.6012 - val_acc: 0.6667\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 64s 944ms/step - loss: 0.5518 - acc: 0.7721 - val_loss: 0.5946 - val_acc: 0.8056\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 67s 990ms/step - loss: 0.5499 - acc: 0.7574 - val_loss: 0.5866 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5502 - acc: 0.7647 - val_loss: 0.6296 - val_acc: 0.6667\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5150 - acc: 0.8162 - val_loss: 0.6129 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5316 - acc: 0.7500 - val_loss: 0.5965 - val_acc: 0.6944\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4919 - acc: 0.8088 - val_loss: 0.6072 - val_acc: 0.6667\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5317 - acc: 0.7794 - val_loss: 0.5796 - val_acc: 0.6667\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 72s 1s/step - loss: 0.5194 - acc: 0.7500 - val_loss: 0.6339 - val_acc: 0.6667\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5228 - acc: 0.7868 - val_loss: 0.5831 - val_acc: 0.6944\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5377 - acc: 0.7426 - val_loss: 0.6016 - val_acc: 0.6667\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5027 - acc: 0.7721 - val_loss: 0.6230 - val_acc: 0.6667\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.5125 - acc: 0.7941 - val_loss: 0.6818 - val_acc: 0.6389\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 63s 923ms/step - loss: 0.5613 - acc: 0.7647 - val_loss: 0.5666 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4581 - acc: 0.8309 - val_loss: 0.5239 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5557 - acc: 0.7647 - val_loss: 0.5721 - val_acc: 0.6667\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4588 - acc: 0.8309 - val_loss: 0.5797 - val_acc: 0.6667\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4359 - acc: 0.8456 - val_loss: 0.6018 - val_acc: 0.6389\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4326 - acc: 0.8235 - val_loss: 0.5944 - val_acc: 0.6667\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4708 - acc: 0.8162 - val_loss: 0.6010 - val_acc: 0.6944\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4250 - acc: 0.8382 - val_loss: 0.5572 - val_acc: 0.7222\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4635 - acc: 0.7941 - val_loss: 0.5796 - val_acc: 0.7222\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4934 - acc: 0.8235 - val_loss: 0.5750 - val_acc: 0.7222\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5029 - acc: 0.8015 - val_loss: 0.7051 - val_acc: 0.5556\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4841 - acc: 0.8088 - val_loss: 0.5946 - val_acc: 0.6667\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 65s 963ms/step - loss: 0.4735 - acc: 0.8162 - val_loss: 0.5779 - val_acc: 0.7222\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 65s 951ms/step - loss: 0.5557 - acc: 0.7279 - val_loss: 0.5997 - val_acc: 0.7222\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5304 - acc: 0.7868 - val_loss: 0.6168 - val_acc: 0.6667\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4333 - acc: 0.8603 - val_loss: 0.5661 - val_acc: 0.7222\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4162 - acc: 0.8676 - val_loss: 0.5584 - val_acc: 0.7778\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5407 - acc: 0.7206 - val_loss: 0.5637 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.5134 - acc: 0.7353 - val_loss: 0.5911 - val_acc: 0.6111\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4097 - acc: 0.8824 - val_loss: 0.7132 - val_acc: 0.6667\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4715 - acc: 0.8235 - val_loss: 0.5529 - val_acc: 0.6667\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4755 - acc: 0.7941 - val_loss: 0.6189 - val_acc: 0.6944\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4009 - acc: 0.8676 - val_loss: 0.6275 - val_acc: 0.7222\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4728 - acc: 0.7868 - val_loss: 0.5904 - val_acc: 0.6667\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 72s 1s/step - loss: 0.4308 - acc: 0.8456 - val_loss: 0.5528 - val_acc: 0.7222\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 63s 924ms/step - loss: 0.4707 - acc: 0.8088 - val_loss: 0.6538 - val_acc: 0.6667\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 67s 982ms/step - loss: 0.4547 - acc: 0.8088 - val_loss: 0.5730 - val_acc: 0.7778\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4059 - acc: 0.8824 - val_loss: 0.5846 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4311 - acc: 0.8309 - val_loss: 0.5911 - val_acc: 0.7222\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4444 - acc: 0.8235 - val_loss: 0.6003 - val_acc: 0.6667\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4578 - acc: 0.7794 - val_loss: 0.6394 - val_acc: 0.6389\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.3904 - acc: 0.8750 - val_loss: 0.5827 - val_acc: 0.7500\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4878 - acc: 0.7647 - val_loss: 0.5822 - val_acc: 0.6944\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.5532 - acc: 0.7426 - val_loss: 0.5732 - val_acc: 0.7222\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4430 - acc: 0.8603 - val_loss: 0.5610 - val_acc: 0.7778\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4363 - acc: 0.8162 - val_loss: 0.5420 - val_acc: 0.7778\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4121 - acc: 0.8529 - val_loss: 0.5648 - val_acc: 0.7778\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 68s 994ms/step - loss: 0.5003 - acc: 0.7426 - val_loss: 0.5562 - val_acc: 0.7222\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 63s 923ms/step - loss: 0.3985 - acc: 0.8603 - val_loss: 0.5760 - val_acc: 0.7222\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4263 - acc: 0.8088 - val_loss: 0.5799 - val_acc: 0.7222\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4774 - acc: 0.7721 - val_loss: 0.6210 - val_acc: 0.6111\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4429 - acc: 0.7941 - val_loss: 0.5482 - val_acc: 0.7778\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.3623 - acc: 0.8824 - val_loss: 0.5757 - val_acc: 0.7222\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4184 - acc: 0.8456 - val_loss: 0.6553 - val_acc: 0.6667\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4104 - acc: 0.8382 - val_loss: 0.6409 - val_acc: 0.6111\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4868 - acc: 0.7868 - val_loss: 0.5655 - val_acc: 0.7778\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.3713 - acc: 0.8750 - val_loss: 0.5761 - val_acc: 0.7222\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.4488 - acc: 0.8309 - val_loss: 0.6141 - val_acc: 0.7222\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 71s 1s/step - loss: 0.3783 - acc: 0.8603 - val_loss: 0.6142 - val_acc: 0.6944\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.3938 - acc: 0.8824 - val_loss: 0.5898 - val_acc: 0.6111\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 64s 948ms/step - loss: 0.4308 - acc: 0.7721 - val_loss: 0.5817 - val_acc: 0.6667\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 66s 967ms/step - loss: 0.3959 - acc: 0.8088 - val_loss: 0.5918 - val_acc: 0.7222\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4186 - acc: 0.8088 - val_loss: 0.5885 - val_acc: 0.6944\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.4099 - acc: 0.8162 - val_loss: 0.5985 - val_acc: 0.7222\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.3811 - acc: 0.8309 - val_loss: 0.5925 - val_acc: 0.7222\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.4069 - acc: 0.8235 - val_loss: 0.5398 - val_acc: 0.8056\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 68s 1s/step - loss: 0.3435 - acc: 0.8750 - val_loss: 0.5568 - val_acc: 0.7222\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.4674 - acc: 0.7794 - val_loss: 0.6046 - val_acc: 0.6667\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 68s 1s/step - loss: 0.4049 - acc: 0.8309 - val_loss: 0.6123 - val_acc: 0.6111\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 69s 1s/step - loss: 0.3960 - acc: 0.8162 - val_loss: 0.5761 - val_acc: 0.7778\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.4161 - acc: 0.8309 - val_loss: 0.5513 - val_acc: 0.8333\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.3454 - acc: 0.8897 - val_loss: 0.5780 - val_acc: 0.7222\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 70s 1s/step - loss: 0.3611 - acc: 0.9118 - val_loss: 0.5419 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 63s 926ms/step - loss: 0.3806 - acc: 0.8529 - val_loss: 0.6084 - val_acc: 0.7222\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 66s 972ms/step - loss: 0.4103 - acc: 0.8603 - val_loss: 0.6255 - val_acc: 0.7222\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "# EPOCHS = 100\n",
    "# INIT_LR = 1e-4\n",
    "# BS = 32\n",
    "# opt = Adam(lr=INIT_LR)\n",
    "model.compile(optimizer=SGD(0.003),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(datagen.flow(X_train, y_train, batch_size=1),\n",
    "                        validation_data=(X_test, y_test), steps_per_epoch=len(X_train), epochs=100, verbose=1)\n",
    "\n",
    "# model.fit(datagen.flow(X_train, y_train, batch_size=32),steps_per_epoch=len(X_train) / 32, epochs=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 219ms/step\n",
      "[0.6255431473255157, 0.7222222222222222]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, batch_size=16)\n",
    "model.predict_classes(X_test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save_weights('final_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
